import pandas as pd
import sqlite3
import os
from datetime import datetime
import re
import glob

class ExcelToSQLite:
    @staticmethod
    def find_excel_files(directory):
        """
        è‡ªåŠ¨æœç´¢ç›®å½•ä¸‹æ‰€æœ‰Excelæ–‡ä»¶
        :param directory: è¦æœç´¢çš„ç›®å½•è·¯å¾„
        :return: Excelæ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        if not os.path.exists(directory):
            raise FileNotFoundError(f"ç›®å½•ä¸å­˜åœ¨ï¼š{directory}")
        
        # æœç´¢.xlsxå’Œ.xlsæ–‡ä»¶
        excel_files = []
        excel_files.extend(glob.glob(os.path.join(directory, "*.xlsx")))
        excel_files.extend(glob.glob(os.path.join(directory, "*.xls")))
        
        return sorted(excel_files)
    
    @classmethod
    def batch_convert_directory(cls, directory, output_db=None):
        """
        æ‰¹é‡è½¬æ¢ç›®å½•ä¸‹æ‰€æœ‰Excelæ–‡ä»¶åˆ°SQLite
        :param directory: Excelæ–‡ä»¶æ‰€åœ¨ç›®å½•
        :param output_db: è¾“å‡ºçš„SQLiteæ•°æ®åº“æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œé»˜è®¤åœ¨ç›®å½•ä¸‹åˆ›å»ºcombined.dbï¼‰
        """
        excel_files = cls.find_excel_files(directory)
        
        if not excel_files:
            print(f"âš ï¸  ç›®å½• {directory} ä¸‹æœªæ‰¾åˆ°Excelæ–‡ä»¶")
            return
        
        print(f"âœ… æ‰¾åˆ° {len(excel_files)} ä¸ªExcelæ–‡ä»¶")
        
        # å¦‚æœæŒ‡å®šäº†è¾“å‡ºæ•°æ®åº“ï¼Œæ‰€æœ‰è¡¨éƒ½ä¼šåˆ›å»ºåœ¨åŒä¸€ä¸ªæ•°æ®åº“ä¸­
        if output_db:
            for i, excel_file in enumerate(excel_files, 1):
                print(f"\n=== å¤„ç†æ–‡ä»¶ {i}/{len(excel_files)}: {os.path.basename(excel_file)} ===")
                # ä½¿ç”¨æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰ä½œä¸ºè¡¨å
                table_name = os.path.splitext(os.path.basename(excel_file))[0]
                try:
                    converter = cls(excel_file, output_db, table_name)
                    converter.export()
                except Exception as e:
                    print(f"âŒ å¤„ç†æ–‡ä»¶å¤±è´¥ {excel_file}: {str(e)}")
        else:
            # å¦åˆ™æ¯ä¸ªExcelæ–‡ä»¶åˆ›å»ºç‹¬ç«‹çš„æ•°æ®åº“
            for i, excel_file in enumerate(excel_files, 1):
                print(f"\n=== å¤„ç†æ–‡ä»¶ {i}/{len(excel_files)}: {os.path.basename(excel_file)} ===")
                try:
                    converter = cls(excel_file)
                    converter.export()
                except Exception as e:
                    print(f"âŒ å¤„ç†æ–‡ä»¶å¤±è´¥ {excel_file}: {str(e)}")
    
    def __init__(self, excel_path, sqlite_path=None, sheet_name=0, table_name=None, has_header=False):
        """
        åˆå§‹åŒ–é…ç½®
        :param excel_path: Excelæ–‡ä»¶è·¯å¾„ï¼ˆå¿…å¡«ï¼‰
        :param sqlite_path: SQLiteæ•°æ®åº“æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ï¼šä¸ExcelåŒç›®å½•åŒå.dbï¼‰
        :param table_name: æ•°æ®è¡¨åï¼ˆé»˜è®¤ï¼šExcelçš„sheetåï¼‰
        :param sheet_name: è¯»å–Excelçš„sheetï¼ˆé»˜è®¤0ï¼šç¬¬ä¸€ä¸ªsheetï¼Œå¯ä¼ sheetåï¼‰
        :param has_header: æ˜¯å¦æœ‰è¡¨å¤´ï¼ˆé»˜è®¤Trueï¼Œè®¾ç½®ä¸ºFalseè‡ªåŠ¨ç”Ÿæˆè¡¨å¤´ï¼‰
        """
        # éªŒè¯Excelæ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(excel_path):
            raise FileNotFoundError(f"Excelæ–‡ä»¶ä¸å­˜åœ¨ï¼š{excel_path}")
        
        self.excel_path = excel_path
        self.sheet_name = sheet_name
        self.has_header = has_header
        
        # é…ç½®SQLiteè·¯å¾„ï¼ˆé»˜è®¤ä¸ExcelåŒç›®å½•ï¼ŒåŒå.dbï¼‰
        self.sqlite_path = sqlite_path or os.path.splitext(excel_path)[0] + ".db"
        
        # æ—¥å¿—å­˜å‚¨
        self.logs = []
        
        # è¯»å–Excelæ•°æ®
        self.df = self._read_excel()
        
        # é…ç½®è¡¨å
        if table_name:
            self.table_name = table_name
        else:
            # ä»Excelæ–‡ä»¶åç”Ÿæˆè¡¨å
            base_name = os.path.basename(self.excel_path)
            self.table_name = os.path.splitext(base_name)[0].replace(' ', '_')
            self.logs.append(f"ğŸ“‹ è‡ªåŠ¨ä»æ–‡ä»¶åç”Ÿæˆè¡¨å: {self.table_name}")
        
        # æ¸…æ´—åˆ—åï¼ˆå»é™¤ç‰¹æ®Šå­—ç¬¦ã€ç©ºæ ¼ï¼Œé¿å…SQLè¯­æ³•é”™è¯¯ï¼‰
        self.df.columns = self._clean_column_names(self.df.columns)

    def _read_excel(self):
        """è¯»å–Excelæ–‡ä»¶ï¼Œè¿”å›DataFrame"""
        try:
            # è‡ªåŠ¨è¯†åˆ«Excelæ ¼å¼ï¼ˆ.xlsx/.xlsï¼‰
            # æ ¹æ®pandasç‰ˆæœ¬è°ƒæ•´å‚æ•°
            read_excel_kwargs = {
                'sheet_name': self.sheet_name,
                'engine': None,  # pandasè‡ªåŠ¨é€‰æ‹©å¼•æ“ï¼ˆopenpyxl/xlrdï¼‰
                'header': 0 if self.has_header else None  # æ ¹æ®has_headerå‚æ•°å†³å®šæ˜¯å¦ä½¿ç”¨ç¬¬ä¸€è¡Œä½œä¸ºè¡¨å¤´
            }
            
            # å°è¯•ä½¿ç”¨keep_default_dtypeå‚æ•°ï¼ˆè¾ƒæ–°ç‰ˆæœ¬pandasæ”¯æŒï¼‰
            try:
                df = pd.read_excel(self.excel_path, **read_excel_kwargs, keep_default_dtype=False)
            except TypeError:
                # å¯¹äºä¸æ”¯æŒè¯¥å‚æ•°çš„pandasç‰ˆæœ¬ï¼Œç§»é™¤è¿™ä¸ªå‚æ•°
                self.logs.append("âš ï¸ å½“å‰pandasç‰ˆæœ¬ä¸æ”¯æŒkeep_default_dtypeå‚æ•°ï¼Œä½¿ç”¨é»˜è®¤æ•°æ®ç±»å‹å¤„ç†")
                df = pd.read_excel(self.excel_path, **read_excel_kwargs)
            
            self.logs.append(f"âœ… æˆåŠŸè¯»å–Excelæ–‡ä»¶ï¼š{self.excel_path}")
            # ä½¿ç”¨æŒ‡å®šçš„sheet_nameè€Œä¸æ˜¯df.nameï¼Œå› ä¸ºdf.nameåœ¨æŸäº›pandasç‰ˆæœ¬ä¸­ä¸å¯é 
            sheet_display = self.sheet_name if isinstance(self.sheet_name, str) else f"ç¬¬{self.sheet_name+1}ä¸ª" if isinstance(self.sheet_name, int) else "æœªçŸ¥"
            self.logs.append(f"ğŸ“Š è¯»å–sheetï¼š{sheet_display}ï¼Œæ•°æ®è¡Œæ•°ï¼š{len(df)}ï¼Œåˆ—æ•°ï¼š{len(df.columns)}")
            
            # å¦‚æœæ²¡æœ‰è¡¨å¤´ï¼Œå°è¯•æ ¹æ®æ•°æ®å†…å®¹æ¨æ–­å¹¶ç”Ÿæˆè¡¨å¤´
            if not self.has_header:
                self.logs.append("â„¹ï¸  æ£€æµ‹åˆ°æ— è¡¨å¤´Excelæ–‡ä»¶ï¼Œæ­£åœ¨ç”Ÿæˆè¡¨å¤´...")
                # å…ˆç”Ÿæˆä¸´æ—¶åˆ—å
                temp_columns = [f"column_{i+1}" for i in range(len(df.columns))]
                df.columns = temp_columns
                
                # å°è¯•æ ¹æ®å‰å‡ è¡Œæ•°æ®æ¨æ–­åˆ—çš„æ€§è´¨å¹¶ç”Ÿæˆæ›´æœ‰æ„ä¹‰çš„åˆ—å
                inferred_columns = self._infer_column_names(df)
                self.logs.append(f"âœ… è‡ªåŠ¨ç”Ÿæˆè¡¨å¤´ï¼š{inferred_columns}")
                df.columns = inferred_columns
            
            return df
        except Exception as e:
            raise RuntimeError(f"è¯»å–Excelå¤±è´¥ï¼š{str(e)}")
    
    def _infer_column_names(self, df):
        """
        æ™ºèƒ½æ¨æ–­åˆ—åï¼Œæ ¹æ®æ•°æ®å†…å®¹è¯†åˆ«å§“åã€ç”µè¯ç­‰ä¿¡æ¯
        :param df: æ— è¡¨å¤´çš„DataFrame
        :return: æ¨æ–­åçš„åˆ—ååˆ—è¡¨
        """
        import re
        from collections import Counter
        
        new_columns = []
        # å·²ä½¿ç”¨çš„åˆ—åï¼Œé¿å…é‡å¤
        used_names = set()
        
        # ç”¨äºè¯†åˆ«ç”µè¯çš„æ­£åˆ™è¡¨è¾¾å¼ï¼ˆç®€å•ç‰ˆæœ¬ï¼Œå¯æ ¹æ®éœ€è¦æ‰©å±•ï¼‰
        phone_pattern = re.compile(r'^1[3-9]\d{9}$')
        # ç”¨äºè¯†åˆ«æ—¥æœŸçš„æ­£åˆ™è¡¨è¾¾å¼ï¼ˆç®€å•ç‰ˆæœ¬ï¼ŒåŒ¹é…YYYY-MM-DDã€YYYY/MM/DDã€YYYY_MM_DDç­‰æ ¼å¼ï¼‰
        date_pattern = re.compile(r'^\d{4}[-_/]\d{1,2}[-_/]\d{1,2}$')
        
        for col_idx, col in enumerate(df.columns):
            # è·å–è¯¥åˆ—çš„éç©ºå€¼æ ·æœ¬
            non_empty_values = df[col].dropna().astype(str)
            if len(non_empty_values) == 0:
                new_name = f'column_{col_idx+1}'
                new_columns.append(new_name)
                continue
            
            # åˆ†ææ ·æœ¬ç‰¹å¾
            sample_values = non_empty_values.head(min(10, len(non_empty_values)))
            
            # åˆ¤æ–­æ˜¯å¦æ˜¯ç”µè¯åˆ—
            is_phone = all(phone_pattern.match(str(val)) for val in sample_values)
            if is_phone and 'phone' not in used_names:
                new_name = 'phone'
                used_names.add(new_name)
                new_columns.append(new_name)
                continue
            
            # åˆ¤æ–­æ˜¯å¦æ˜¯æ—¥æœŸåˆ—
            is_date = all(date_pattern.match(str(val)) for val in sample_values)
            if is_date and 'date' not in used_names:
                new_name = 'date'
                used_names.add(new_name)
                new_columns.append(new_name)
                continue
            
            # åˆ¤æ–­æ˜¯å¦å¯èƒ½æ˜¯å§“ååˆ—ï¼ˆä¸­æ–‡åå­—ç‰¹å¾ï¼š2-4ä¸ªæ±‰å­—ï¼‰
            chinese_name_pattern = re.compile(r'^[\u4e00-\u9fa5]{2,4}$')
            is_chinese_name = all(chinese_name_pattern.match(str(val)) for val in sample_values)
            if is_chinese_name and 'name' not in used_names:
                new_name = 'name'
                used_names.add(new_name)
                new_columns.append(new_name)
                continue
            
            # åˆ¤æ–­æ˜¯å¦æ˜¯çº¯æ•°å­—åˆ—ï¼ˆå¯èƒ½æ˜¯IDã€ç¼–å·ç­‰ï¼‰
            is_numeric = all(str(val).isdigit() for val in sample_values)
            if is_numeric and 'id' not in used_names:
                new_name = 'id'
                used_names.add(new_name)
                new_columns.append(new_name)
                continue
            
            # åˆ¤æ–­æ˜¯å¦å¯èƒ½æ˜¯çŠ¶æ€æˆ–ç±»åˆ«åˆ—ï¼ˆæ–‡æœ¬è¾ƒçŸ­ï¼Œé‡å¤å€¼è¾ƒå¤šï¼‰
            if len(sample_values) > 0:
                # è®¡ç®—å”¯ä¸€å€¼æ¯”ä¾‹
                unique_ratio = len(sample_values.unique()) / len(sample_values)
                # å¦‚æœå”¯ä¸€å€¼æ¯”ä¾‹ä½ä¸”æ–‡æœ¬è¾ƒçŸ­ï¼Œå¯èƒ½æ˜¯çŠ¶æ€åˆ—
                if unique_ratio < 0.5 and all(len(str(val)) < 20 for val in sample_values) and 'status' not in used_names:
                    new_name = 'status'
                    used_names.add(new_name)
                    new_columns.append(new_name)
                    continue
            
            # é»˜è®¤å‘½åæ–¹æ¡ˆ
            counter = 1
            base_name = 'remark'
            new_name = base_name
            while new_name in used_names:
                new_name = f'{base_name}_{counter}'
                counter += 1
            used_names.add(new_name)
            new_columns.append(new_name)
        
        # è®°å½•æ¨æ–­çš„åˆ—åï¼Œä½†ä¸ä¿®æ”¹dfçš„åˆ—åï¼ˆç”±è°ƒç”¨æ–¹æ³•å¤„ç†ï¼‰
        self.logs.append(f"ğŸ” æ™ºèƒ½æ¨æ–­çš„åˆ—å: {new_columns}")
        return new_columns

    def _clean_column_names(self, columns):
        """æ¸…æ´—åˆ—åï¼šå»é™¤ç‰¹æ®Šå­—ç¬¦ã€ç©ºæ ¼ï¼Œæ›¿æ¢ä¸ºä¸‹åˆ’çº¿ï¼Œé¿å…SQLè¯­æ³•é”™è¯¯"""
        cleaned = []
        for col in columns:
            # å»é™¤å‰åç©ºæ ¼ï¼Œæ›¿æ¢ä¸­é—´ç©ºæ ¼/ç‰¹æ®Šå­—ç¬¦ä¸ºä¸‹åˆ’çº¿
            clean_col = re.sub(r'[\s\W]+', '_', str(col).strip())
            # å»é™¤å¼€å¤´/ç»“å°¾çš„ä¸‹åˆ’çº¿
            clean_col = clean_col.strip('_')
            # è‹¥åˆ—åä¸ºç©ºï¼Œè‡ªåŠ¨å‘½åä¸ºcol_åºå·
            if not clean_col:
                clean_col = f"col_{len(cleaned) + 1}"
            cleaned.append(clean_col)
        self.logs.append(f"ğŸ”§ æ¸…æ´—ååˆ—åï¼š{cleaned}")
        return cleaned

    def _infer_column_type(self, series):
        """æ¨æ–­åˆ—çš„æ•°æ®ç±»å‹ï¼Œæ˜ å°„ä¸ºSQLiteç±»å‹ï¼ˆTEXT/INTEGER/REAL/DATEï¼‰"""
        import re
        
        # å¤„ç†ç©ºå€¼åˆ—ï¼ˆå…¨éƒ¨ä¸ºNaNï¼‰
        if series.isna().all():
            return "TEXT"
        
        # ä¼˜å…ˆæ£€æŸ¥æ˜¯å¦ä¸ºç”µè¯å·ç åˆ—ï¼ˆ11ä½æ‰‹æœºå·ç æ ¼å¼ï¼‰
        phone_pattern = re.compile(r'^1[3-9]\d{9}$')
        try:
            # å°†éç©ºå€¼è½¬ä¸ºå­—ç¬¦ä¸²å¹¶æ£€æŸ¥æ˜¯å¦åŒ¹é…ç”µè¯å·ç æ ¼å¼
            is_phone = series.dropna().astype(str).apply(lambda x: bool(phone_pattern.match(str(x)))).all()
            if is_phone:
                return "TEXT"  # ç”µè¯å·ç ä½œä¸ºæ–‡æœ¬å­˜å‚¨
        except:
            pass
        
        # å°è¯•è½¬æ¢ä¸ºæ•´æ•°ç±»å‹
        try:
            # æ’é™¤æµ®ç‚¹å‹ï¼ˆå¦‚2.0ï¼‰ï¼Œä»…çº¯æ•´æ•°
            if series.dropna().apply(lambda x: isinstance(x, int) or (isinstance(x, float) and x.is_integer())).all():
                return "INTEGER"
        except:
            pass
        
        # å°è¯•è½¬æ¢ä¸ºæµ®ç‚¹å‹
        try:
            pd.to_numeric(series.dropna(), errors='raise')
            return "REAL"
        except:
            pass
        
        # å°è¯•è½¬æ¢ä¸ºæ—¥æœŸç±»å‹ï¼ˆåœ¨æ•°å€¼ç±»å‹ä¹‹åï¼Œé¿å…å°†æ•°å€¼é”™è¯¯è¯†åˆ«ä¸ºæ—¥æœŸï¼‰
        try:
            pd.to_datetime(series.dropna(), errors='raise')
            return "TEXT"  # SQLiteæ— DATEç±»å‹ï¼Œç”¨TEXTå­˜å‚¨ï¼ˆISOæ ¼å¼ï¼‰
        except:
            pass
        
        # é»˜è®¤æ–‡æœ¬ç±»å‹
        return "TEXT"

    def _generate_create_table_sql(self):
        """æ ¹æ®DataFrameç”ŸæˆSQLå»ºè¡¨è¯­å¥"""
        # æ¨æ–­æ¯åˆ—çš„æ•°æ®ç±»å‹
        column_types = {col: self._infer_column_type(self.df[col]) for col in self.df.columns}
        self.logs.append(f"ğŸ“‹ åˆ—ç±»å‹æ¨æ–­ç»“æœï¼š{column_types}")
        
        # æ‹¼æ¥SQLå­—æ®µï¼ˆåˆ—å ç±»å‹ï¼‰
        columns_sql = ", ".join([f"`{col}` {dtype}" for col, dtype in column_types.items()])
        
        # ç”Ÿæˆå»ºè¡¨SQLï¼ˆIF NOT EXISTS é¿å…é‡å¤åˆ›å»ºï¼‰
        create_sql = f"""
        CREATE TABLE IF NOT EXISTS `{self.table_name}` (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            {columns_sql},
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
        """
        return create_sql.strip()

    def _process_data(self):
        """å¤„ç†æ•°æ®ï¼šè½¬æ¢æ—¥æœŸæ ¼å¼ã€å¤„ç†ç©ºå€¼"""
        import re
        
        df_processed = self.df.copy()
        
        for col in df_processed.columns:
            # å¤„ç†æ—¥æœŸåˆ—ï¼ˆè½¬æ¢ä¸ºISOæ ¼å¼å­—ç¬¦ä¸²ï¼‰
            try:
                # æ£€æŸ¥æ˜¯å¦ä¸ºç”µè¯å·ç åˆ—ï¼ˆé¿å…å°†ç”µè¯å·ç è½¬æ¢ä¸ºæ—¥æœŸï¼‰
                phone_pattern = re.compile(r'^1[3-9]\d{9}$')
                is_phone = False
                try:
                    # é‡‡æ ·æ£€æŸ¥æ˜¯å¦ä¸ºç”µè¯å·ç åˆ—
                    non_empty_values = df_processed[col].dropna()
                    if len(non_empty_values) > 0:
                        sample_size = min(5, len(non_empty_values))
                        sample_values = non_empty_values.head(sample_size).astype(str)
                        is_phone = all(bool(phone_pattern.match(str(val))) for val in sample_values)
                except:
                    pass
                
                # å¦‚æœä¸æ˜¯ç”µè¯å·ç åˆ—ï¼Œæ‰å°è¯•æ—¥æœŸè½¬æ¢
                if not is_phone and self._infer_column_type(df_processed[col]) == "TEXT":
                    # å°è¯•è½¬æ¢ä¸ºæ—¥æœŸ
                    df_processed[col] = pd.to_datetime(df_processed[col], errors='ignore')
                    # å¯¹æˆåŠŸè½¬æ¢çš„æ—¥æœŸï¼Œæ ¹æ®åŸå§‹æ•°æ®ç²¾åº¦åŠ¨æ€è°ƒæ•´æ ¼å¼
                    # åªè¾“å‡ºæ—¥æœŸéƒ¨åˆ†ï¼Œä¸æ·»åŠ T00:00:00
                    df_processed[col] = df_processed[col].apply(
                        lambda x: x.strftime('%Y-%m-%d') if pd.notna(x) and isinstance(x, datetime) else x
                    )
            except:
                pass
        
        # å¤„ç†ç©ºå€¼ï¼ˆæ›¿æ¢ä¸ºNoneï¼ŒSQLiteä¸­å­˜å‚¨ä¸ºNULLï¼‰
        df_processed = df_processed.where(pd.notna(df_processed), None)
        return df_processed

    def export(self):
        """æ‰§è¡Œå¯¼å‡ºï¼šåˆ›å»ºæ•°æ®åº“ã€å»ºè¡¨ã€æ’å…¥æ•°æ®"""
        conn = None
        cursor = None
        try:
            # 1. è¿æ¥SQLiteæ•°æ®åº“ï¼ˆä¸å­˜åœ¨åˆ™è‡ªåŠ¨åˆ›å»ºï¼‰
            self.logs.append(f"ğŸ”„ æ­£åœ¨è¿æ¥/åˆ›å»ºSQLiteæ•°æ®åº“ï¼š{self.sqlite_path}")
            conn = sqlite3.connect(self.sqlite_path)
            # è®¾ç½®æ›´ä¸¥æ ¼çš„é”™è¯¯å¤„ç†æ¨¡å¼
            conn.execute("PRAGMA foreign_keys = ON")
            conn.execute("PRAGMA synchronous = NORMAL")
            cursor = conn.cursor()
            self.logs.append(f"ğŸ“¦ æˆåŠŸè¿æ¥/åˆ›å»ºSQLiteæ•°æ®åº“ï¼š{self.sqlite_path}")
            
            try:
                # 2. ç”Ÿæˆå¹¶æ‰§è¡Œå»ºè¡¨SQL
                # ä¸ºç¡®ä¿è¡¨ç»“æ„æ­£ç¡®ï¼Œå…ˆåˆ é™¤å·²å­˜åœ¨çš„åŒåè¡¨
                cursor.execute(f"DROP TABLE IF EXISTS `{self.table_name}`")
                conn.commit()
                
                create_sql = self._generate_create_table_sql()
                self.logs.append(f"âš™ï¸  å»ºè¡¨SQLï¼š\n{create_sql}")
                cursor.execute(create_sql)
                conn.commit()
                self.logs.append(f"âœ… æˆåŠŸåˆ›å»ºè¡¨ï¼š{self.table_name}")
                
                # 3. å¤„ç†æ•°æ®ï¼ˆæ—¥æœŸã€ç©ºå€¼ï¼‰
                try:
                    df_processed = self._process_data()
                    self.logs.append(f"ğŸ“‹ æ•°æ®é¢„å¤„ç†å®Œæˆï¼Œå‡†å¤‡æ’å…¥")
                    
                    # 4. æ‰¹é‡æ’å…¥æ•°æ®
                    if len(df_processed) > 0:
                        # ç”Ÿæˆæ’å…¥SQLï¼Œåªæ’å…¥Excelä¸­çš„åˆ—æ•°æ®ï¼Œidå’Œcreated_atç”±æ•°æ®åº“è‡ªåŠ¨ç”Ÿæˆ
                        columns = ", ".join([f"`{col}`" for col in df_processed.columns])
                        placeholders = ", ".join(["?" for _ in df_processed.columns])
                        insert_sql = f"INSERT INTO `{self.table_name}` ({columns}) VALUES ({placeholders})"
                        self.logs.append(f"ğŸ”§ æ’å…¥SQLï¼š{insert_sql[:100]}..." if len(insert_sql) > 100 else f"ğŸ”§ æ’å…¥SQLï¼š{insert_sql}")
                        
                        # è½¬æ¢DataFrameä¸ºå…ƒç»„åˆ—è¡¨ï¼ˆSQLiteæ’å…¥æ ¼å¼ï¼‰
                        data_tuples = []
                        for row in df_processed.values:
                            # å¤„ç†å¯èƒ½çš„Noneå€¼å’Œç‰¹æ®Šç±»å‹
                            processed_row = []
                            for val in row:
                                if pd.isna(val):
                                    processed_row.append(None)
                                elif isinstance(val, datetime):
                                    processed_row.append(val.strftime('%Y-%m-%d'))
                                else:
                                    processed_row.append(val)
                            data_tuples.append(tuple(processed_row))
                        
                        # æ‰¹é‡æ‰§è¡Œæ’å…¥ï¼ˆæ•ˆç‡è¿œé«˜äºå¾ªç¯æ’å…¥ï¼‰
                        self.logs.append(f"ğŸ“Š å‡†å¤‡æ’å…¥ {len(data_tuples)} æ¡æ•°æ®")
                        cursor.executemany(insert_sql, data_tuples)
                        conn.commit()
                        
                        self.logs.append(f"âœ… æˆåŠŸæ’å…¥ {cursor.rowcount} æ¡æ•°æ®")
                    else:
                        self.logs.append("â„¹ï¸  æ— æ•°æ®å¯æ’å…¥ï¼ˆExcelè¡¨æ ¼ä¸ºç©ºï¼‰")
                    
                    # 5. éªŒè¯æ•°æ®ï¼ˆå¯é€‰ï¼šæŸ¥è¯¢å‰5æ¡æ•°æ®ï¼‰
                    try:
                        cursor.execute(f"SELECT * FROM `{self.table_name}` LIMIT 5")
                        sample_data = cursor.fetchall()
                        if sample_data:
                            self.logs.append(f"ğŸ“ æ•°æ®æ ·ä¾‹ï¼ˆå‰5æ¡ï¼‰ï¼š")
                            # è·å–å®é™…çš„åˆ—åï¼ˆåŒ…æ‹¬è‡ªåŠ¨ç”Ÿæˆçš„idå’Œcreated_atï¼‰
                            cursor.execute(f"PRAGMA table_info(`{self.table_name}`)")
                            table_columns = [col[1] for col in cursor.fetchall()]
                            for row in sample_data:
                                row_dict = dict(zip(table_columns, row))
                                # æ ¼å¼åŒ–è¾“å‡ºï¼Œé¿å…è¿‡é•¿
                                formatted_row = {}
                                for k, v in row_dict.items():
                                    v_str = str(v)
                                    if len(v_str) > 50:  # é™åˆ¶è¾“å‡ºé•¿åº¦
                                        v_str = v_str[:50] + "..."
                                    formatted_row[k] = v_str
                                self.logs.append(formatted_row)
                    except Exception as verify_error:
                        self.logs.append(f"âš ï¸  æ•°æ®éªŒè¯æ—¶å‘ç”Ÿè­¦å‘Šï¼š{str(verify_error)}")
                except Exception as data_error:
                    conn.rollback()
                    raise RuntimeError(f"æ•°æ®å¤„ç†å¤±è´¥ï¼š{str(data_error)}")
                    
            except Exception as table_error:
                conn.rollback()
                raise RuntimeError(f"è¡¨åˆ›å»º/æ“ä½œå¤±è´¥ï¼š{str(table_error)}")
                
        except Exception as e:
            # ç¡®ä¿è¿æ¥è¢«å…³é—­
            if 'conn' in locals() and conn:
                try:
                    conn.rollback()
                except:
                    pass
            error_msg = f"å¯¼å‡ºå¤±è´¥ï¼š{str(e)}"
            self.logs.append(f"âŒ {error_msg}")
            # å³ä½¿å‡ºé”™ä¹Ÿè¦æ‰“å°æ—¥å¿—
            self._print_logs()
            raise RuntimeError(error_msg)
        finally:
            # ç¡®ä¿èµ„æºè¢«é‡Šæ”¾
            if cursor:
                try:
                    cursor.close()
                except:
                    pass
            if conn:
                try:
                    conn.close()
                except:
                    pass
                
        self.logs.append(f"ğŸ”š å¯¼å‡ºå®Œæˆï¼SQLiteæ–‡ä»¶è·¯å¾„ï¼š{self.sqlite_path}")
        
        # æ‰“å°æ‰€æœ‰æ—¥å¿—
        self._print_logs()
        
        return self.sqlite_path  # è¿”å›ç”Ÿæˆçš„æ•°æ®åº“è·¯å¾„ï¼Œä¾¿äºé“¾å¼è°ƒç”¨

    def _print_logs(self):
        """æ‰“å°æ‰§è¡Œæ—¥å¿—"""
        print("\n" + "="*50)
        print("ğŸ“Š Excelè½¬SQLiteæ‰§è¡Œæ—¥å¿—")
        print("="*50)
        for log in self.logs:
            print(log)
        print("="*50 + "\n")

# -------------------------- ç¤ºä¾‹ä½¿ç”¨ --------------------------
if __name__ == "__main__":
    print("ğŸš€ ExcelToSQLite å·¥å…·å¯åŠ¨")
    print("ğŸ“š æä¾›ä»¥ä¸‹åŠŸèƒ½ï¼š")
    print("  1. å•ä¸ªExcelæ–‡ä»¶è½¬æ¢ï¼ˆé»˜è®¤å°†ç¬¬ä¸€è¡Œä½œä¸ºæ•°æ®è€Œéè¡¨å¤´ï¼‰")
    print("  2. æ™ºèƒ½åˆ—åæ¨æ–­ï¼šè‡ªåŠ¨è¯†åˆ«å§“åã€ç”µè¯ã€æ—¥æœŸç­‰ä¿¡æ¯ï¼Œç”Ÿæˆnameã€phoneç­‰æœ‰æ„ä¹‰çš„åˆ—å")
    print("  3. è‡ªåŠ¨ä¸ºæ¯è¡Œæ•°æ®ç”Ÿæˆè¿ç»­å”¯ä¸€çš„ID")
    print("  4. è‡ªåŠ¨æœç´¢ç›®å½•ä¸‹æ‰€æœ‰Excelæ–‡ä»¶å¹¶æ‰¹é‡è½¬æ¢")
    print()
    
    # ç¤ºä¾‹1ï¼šè½¬æ¢å•ä¸ªExcelæ–‡ä»¶ï¼ˆé»˜è®¤å°†ç¬¬ä¸€è¡Œä½œä¸ºæ•°æ®ï¼Œè‡ªåŠ¨æ¨æ–­åˆ—åï¼‰
    # å–æ¶ˆæ³¨é‡Šä¸‹é¢çš„ä»£ç å—å³å¯ä½¿ç”¨
    # print("\n=== ç¤ºä¾‹1ï¼šè½¬æ¢å•ä¸ªExcelæ–‡ä»¶ï¼ˆè‡ªåŠ¨å¤„ç†ï¼‰ ===")
    # try:
    #     EXCEL_PATH = "data.xlsx"  # ä½ çš„Excelæ–‡ä»¶è·¯å¾„ï¼ˆå¿…å¡«ï¼‰
    #     SQLITE_PATH = "mydatabase.db"  # è¾“å‡ºçš„SQLiteæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
    #     TABLE_NAME = "mytable"  # æ•°æ®è¡¨åï¼ˆå¯é€‰ï¼‰
    #     SHEET_NAME = 0  # è¯»å–çš„sheetï¼ˆ0=ç¬¬ä¸€ä¸ªsheetï¼Œå¯ä¼ sheetåå¦‚"ç”¨æˆ·æ•°æ®"ï¼‰
    #     
    #     # åˆ›å»ºè½¬æ¢å™¨å®ä¾‹ï¼ˆé»˜è®¤has_header=Falseï¼Œå°†ç¬¬ä¸€è¡Œä½œä¸ºæ•°æ®å¤„ç†ï¼‰
    #     converter = ExcelToSQLite(
    #         excel_path=EXCEL_PATH,
    #         sqlite_path=SQLITE_PATH,
    #         table_name=TABLE_NAME,
    #         sheet_name=SHEET_NAME
    #         # has_header=False  # é»˜è®¤å€¼ï¼Œè‡ªåŠ¨æ¨æ–­åˆ—å
    #     )
    #     
    #     # æ‰§è¡Œå¯¼å‡º
    #     db_path = converter.export()
    #     print(f"ğŸ“Œ æ•°æ®åº“å·²ç”Ÿæˆï¼š{db_path}")
    #     print(f"âœ… å·²è‡ªåŠ¨ä¸ºæ¯è¡Œæ•°æ®ç”Ÿæˆè¿ç»­å”¯ä¸€ID")
    #     print(f"âœ… å·²æ™ºèƒ½æ¨æ–­åˆ—åï¼ˆå¦‚nameã€phoneã€dateç­‰ï¼‰")
    # except Exception as e:
    #     print(f"\nâŒ é”™è¯¯ï¼š{str(e)}")
    
    # ç¤ºä¾‹2ï¼šå¼ºåˆ¶å°†ç¬¬ä¸€è¡Œä½œä¸ºè¡¨å¤´ï¼ˆå½“Excelæ–‡ä»¶ç¡®å®æœ‰è¡¨å¤´æ—¶ä½¿ç”¨ï¼‰
    # å–æ¶ˆæ³¨é‡Šä¸‹é¢çš„ä»£ç å—å³å¯ä½¿ç”¨
    # print("\n=== ç¤ºä¾‹2ï¼šå°†ç¬¬ä¸€è¡Œä½œä¸ºè¡¨å¤´å¤„ç† ===")
    # try:
    #     converter = ExcelToSQLite(
    #         excel_path="data_with_header.xlsx",
    #         has_header=True,  # æ˜ç¡®æŒ‡å®šæ–‡ä»¶æœ‰è¡¨å¤´
    #         table_name="data_with_original_headers"  # è‡ªå®šä¹‰è¡¨å
    #     )
    #     converter.export()
    # except Exception as e:
    #     print(f"\nâŒ é”™è¯¯ï¼š{str(e)}")
    
    # ç¤ºä¾‹3ï¼šæ‰¹é‡è½¬æ¢ç›®å½•ä¸‹æ‰€æœ‰Excelæ–‡ä»¶åˆ°ç‹¬ç«‹æ•°æ®åº“
    print("\n=== ç¤ºä¾‹3ï¼šæ‰¹é‡è½¬æ¢ç›®å½•ä¸‹æ‰€æœ‰Excelæ–‡ä»¶ ===")
    try:
        # æ‰¹é‡è½¬æ¢å½“å‰ç›®å½•ä¸‹çš„excelæ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰Excelæ–‡ä»¶
        EXCEL_DIR = os.path.join(os.path.dirname(__file__), "excel")
        print(f"ğŸ” æ­£åœ¨æ‰«æç›®å½•ï¼š{EXCEL_DIR}")
        
        # æ–¹æ¡ˆAï¼šæ¯ä¸ªExcelæ–‡ä»¶ç”Ÿæˆç‹¬ç«‹çš„æ•°æ®åº“æ–‡ä»¶
        print("\nğŸ“‹ æ–¹æ¡ˆAï¼šæ¯ä¸ªExcelæ–‡ä»¶ç”Ÿæˆç‹¬ç«‹æ•°æ®åº“")
        ExcelToSQLite.batch_convert_directory(EXCEL_DIR)
        
        # æ–¹æ¡ˆBï¼šæ‰€æœ‰Excelæ–‡ä»¶è½¬æ¢åˆ°åŒä¸€ä¸ªæ•°æ®åº“ï¼ˆå–æ¶ˆæ³¨é‡Šä½¿ç”¨ï¼‰
        # print("\nğŸ“‹ æ–¹æ¡ˆBï¼šæ‰€æœ‰Excelæ–‡ä»¶è½¬æ¢åˆ°åŒä¸€ä¸ªæ•°æ®åº“")
        # OUTPUT_DB = os.path.join(EXCEL_DIR, "all_excel_data.db")
        # ExcelToSQLite.batch_convert_directory(EXCEL_DIR, OUTPUT_DB)
        # print(f"\nğŸ“Œ æ‰€æœ‰Excelæ•°æ®å·²åˆå¹¶åˆ°ï¼š{OUTPUT_DB}")
        
    except FileNotFoundError as e:
        print(f"\nâŒ ç›®å½•ä¸å­˜åœ¨ï¼š{str(e)}")
    except Exception as e:
        print(f"\nâŒ æ‰¹é‡è½¬æ¢å¤±è´¥ï¼š{str(e)}")
    
    print("\nğŸ‰ ä»»åŠ¡å®Œæˆï¼")
    print("ğŸ’¡ ä½¿ç”¨è¯´æ˜ï¼š")
    print("  - é»˜è®¤è¡Œä¸ºï¼šå°†Excelçš„ç¬¬ä¸€è¡Œä½œä¸ºæ•°æ®å¤„ç†ï¼Œè‡ªåŠ¨æ¨æ–­åˆ—åä¸ºnameã€phoneã€dateç­‰")
    print("  - å¦‚éœ€å°†ç¬¬ä¸€è¡Œä½œä¸ºè¡¨å¤´ï¼šè®¾ç½® has_header=True å‚æ•°")
    print("  - æ™ºèƒ½åˆ—åè¯†åˆ«ï¼šè‡ªåŠ¨æ£€æµ‹å§“åï¼ˆä¸­æ–‡ï¼‰ã€ç”µè¯ï¼ˆ11ä½æ‰‹æœºå·ï¼‰ã€æ—¥æœŸã€IDç­‰æ•°æ®ç±»å‹")
    print("  - ç”µè¯æ ¼å¼ä¿æŠ¤ï¼šä¼˜å…ˆè¯†åˆ«11ä½æ‰‹æœºå·ç æ ¼å¼ï¼Œé¿å…é”™è¯¯è½¬æ¢ä¸ºæ—¶é—´æˆ³")
    print("  - æ—¥æœŸæ ¼å¼ä¼˜åŒ–ï¼šæ—¥æœŸä¼šä»¥çº¯YYYY-MM-DDæ ¼å¼æ˜¾ç¤ºï¼Œä¸åŒ…å«T00:00:00æ—¶é—´ä¿¡æ¯")
    print("  - è‡ªåŠ¨ç”Ÿæˆè¿ç»­IDï¼šæ¯æ¡è®°å½•éƒ½ä¼šæœ‰å”¯ä¸€çš„è‡ªå¢ä¸»é”®ID")
    print("  - è‡ªå®šä¹‰è¡¨åï¼šé€šè¿‡ table_name å‚æ•°è®¾ç½®æ•°æ®è¡¨åç§°")
    print("  - æ‰¹é‡å¤„ç†ï¼šä½¿ç”¨ batch_convert_directory æ–¹æ³•å¤„ç†ç›®å½•ä¸‹æ‰€æœ‰Excelæ–‡ä»¶")